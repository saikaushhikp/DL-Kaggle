{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9717c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from google.colab import drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab3acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef23baaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_and_download():\n",
    "    # Mount Drive\n",
    "    try:\n",
    "        drive.mount('/content/drive')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Login to Kaggle\n",
    "    kagglehub.login()\n",
    "\n",
    "    # Download competition data\n",
    "    kaggle_competition_dl_f_2025_path = kagglehub.competition_download('kaggle-competition-dl-f-2025')\n",
    "\n",
    "    print('Data source import complete.')\n",
    "    print(kaggle_competition_dl_f_2025_path)\n",
    "\n",
    "    # List files\n",
    "    for dirname, _, filenames in os.walk('/root/.cache/kagglehub/competitions'):\n",
    "        for filename in filenames:\n",
    "            print(os.path.join(dirname, filename))\n",
    "            \n",
    "    return \n",
    "\n",
    "setup_and_download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8066fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiSpectralDataset(Dataset):\n",
    "    def __init__(self, X, Y, indices, augment=False, mean=None, std=None, compute_stats=False):\n",
    "        \"\"\"\n",
    "        X, Y          : mmap arrays or numpy arrays\n",
    "        indices       : list of sample indices\n",
    "        mean, std     : optional precomputed normalization stats\n",
    "        compute_stats : if True -> compute mean/std from X[indices]\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.indices = indices\n",
    "        self.augment = augment\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # Compute normalization stats (ONLY ON TRAINING SET)\n",
    "        # -------------------------------------------------------\n",
    "        if compute_stats:\n",
    "            C = X.shape[1]\n",
    "            mean = np.zeros(C, dtype=np.float64)\n",
    "            M2   = np.zeros(C, dtype=np.float64)\n",
    "            count = 0\n",
    "\n",
    "            for idx in indices:\n",
    "                x = X[idx].astype(np.float32)     # convert to float32\n",
    "                pixels = x.reshape(C, -1)\n",
    "                count_new = pixels.shape[1]\n",
    "\n",
    "                # incremental mean/std update (Welford algorithm)\n",
    "                delta = pixels.mean(axis=1) - mean\n",
    "                mean += delta * (count_new / (count + count_new))\n",
    "\n",
    "                M2 += ((pixels - mean[:, None])**2).sum(axis=1)\n",
    "\n",
    "                count += count_new\n",
    "\n",
    "            self.mean = mean.astype(np.float32)\n",
    "            self.std = np.sqrt(M2 / count).astype(np.float32) + 1e-6\n",
    "\n",
    "        else:\n",
    "            self.mean = mean       # use externally provided stats\n",
    "            self.std  = std\n",
    "        # -------------------------------------------------------\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx = self.indices[i]\n",
    "\n",
    "        #  Load image \n",
    "        img = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "\n",
    "        # Apply normalization if available \n",
    "        if self.mean is not None and self.std is not None:\n",
    "            mean = torch.tensor(self.mean, dtype=torch.float32)[:, None, None]\n",
    "            std  = torch.tensor(self.std, dtype=torch.float32)[:, None, None]\n",
    "            img = (img - mean) / std\n",
    "\n",
    "        # TEST MODE \n",
    "        if self.Y is None:\n",
    "            return img\n",
    "\n",
    "        # TRAIN / VAL MODE \n",
    "        mask = torch.tensor(self.Y[idx], dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        return img, mask\n",
    "    \n",
    "\n",
    "# -----------------------------\n",
    "# Basic building blocks\n",
    "# -----------------------------\n",
    "\n",
    "class ConvBnAct(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size=3, padding=1, stride=1, dilation=1, act='leaky', bias=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_ch)\n",
    "        \n",
    "        if act == 'leaky':\n",
    "            self.act = nn.LeakyReLU(0.2, inplace=True)\n",
    "        elif act == 'relu':\n",
    "            self.act = nn.ReLU(inplace=True)\n",
    "        else:\n",
    "            self.act = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "\n",
    "class ResidualConv(nn.Module):\n",
    "    \"\"\"Two convs with residual (projection when channels differ).\"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvBnAct(in_ch, out_ch)\n",
    "        self.conv2 = ConvBnAct(out_ch, out_ch)\n",
    "        self.need_proj = (in_ch != out_ch)\n",
    "        if self.need_proj:\n",
    "            self.proj = nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
    "            self.bn_proj = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.need_proj:\n",
    "            identity = self.bn_proj(self.proj(identity))\n",
    "        return out + identity\n",
    "\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        r = max(1, channels // reduction)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(channels, r, 1, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(r, channels, 1, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return x * self.fc(self.pool(x))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# MiniInception with residual\n",
    "# -----------------------------\n",
    "class MiniInceptionRes(nn.Module):\n",
    "    \"\"\"\n",
    "    Mini-inception with three stages, residual connection.\n",
    "    Each split uses one 3x3 and one dilated 3x3 conv.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        assert out_ch % 2 == 0, \"out_channels must be divisible by 2\"\n",
    "        half = out_ch // 2\n",
    "        \n",
    "        # stage 1\n",
    "        self.c1l = ConvBnAct(in_ch, half, padding=1, dilation=1, act='leaky')\n",
    "        self.c1r = ConvBnAct(in_ch, half, padding=2, dilation=2, act='leaky')\n",
    "        \n",
    "        # stage 2\n",
    "        self.c2l = ConvBnAct(out_ch, half, padding=1, dilation=1, act='leaky')\n",
    "        self.c2r = ConvBnAct(out_ch, half, padding=2, dilation=2, act='leaky')\n",
    "        \n",
    "        # stage 3\n",
    "        self.c3l = ConvBnAct(out_ch, half, padding=1, dilation=1, act='leaky')\n",
    "        self.c3r = ConvBnAct(out_ch, half, padding=2, dilation=2, act='leaky')\n",
    "\n",
    "        self.need_proj = (in_ch != out_ch)\n",
    "        if self.need_proj:\n",
    "            self.proj = nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
    "            self.bn_proj = nn.BatchNorm2d(out_ch)\n",
    "        self.act = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = torch.cat((self.c1l(x), self.c1r(x)), dim=1)  # out_ch\n",
    "        y = torch.cat((self.c2l(y), self.c2r(y)), dim=1)\n",
    "        y = torch.cat((self.c3l(y), self.c3r(y)), dim=1)\n",
    "        ident = x\n",
    "        if self.need_proj:\n",
    "            ident = self.bn_proj(self.proj(ident))\n",
    "        return self.act(y + ident)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Corrected MFNet (channel-safe)\n",
    "# -----------------------------\n",
    "class MFNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Fully corrected MFNet:\n",
    "      - Clean channel bookkeeping to avoid concat mismatches\n",
    "      - Residual mini-inceptions\n",
    "      - Optional SE after fusion\n",
    "      - Deep supervision heads\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch=16, n_class=1, use_se=True, deep_supervision=True):\n",
    "        super().__init__()\n",
    "        self.n_class = n_class\n",
    "        self.use_se = use_se\n",
    "        self.deep_supervision = deep_supervision\n",
    "\n",
    "        # choose widths (bigger than original MFNet)\n",
    "        # level indices: 1..5 (1 shallow -> 5 deepest)\n",
    "        rgb_ch = [32, 96, 160, 256, 320]    # channels at levels 1..5 for RGB\n",
    "        inf_ch = [32, 64, 96, 128, 160]     # channels at levels 1..5 for INF\n",
    "\n",
    "        # RGB branch\n",
    "        self.conv1_rgb   = ResidualConv(3, rgb_ch[0])\n",
    "        self.conv2_1_rgb = ResidualConv(rgb_ch[0], rgb_ch[1])\n",
    "        self.conv2_2_rgb = ResidualConv(rgb_ch[1], rgb_ch[1])\n",
    "        self.conv3_1_rgb = ResidualConv(rgb_ch[1], rgb_ch[2])\n",
    "        self.conv3_2_rgb = ResidualConv(rgb_ch[2], rgb_ch[2])\n",
    "        self.conv4_rgb   = MiniInceptionRes(rgb_ch[2], rgb_ch[3])\n",
    "        self.conv5_rgb   = MiniInceptionRes(rgb_ch[3], rgb_ch[4])\n",
    "\n",
    "        # INF branch (if present)\n",
    "        self.inf_in_ch = max(0, in_ch - 3)\n",
    "        if self.inf_in_ch > 0:\n",
    "            self.conv1_inf   = ResidualConv(self.inf_in_ch, inf_ch[0])\n",
    "            self.conv2_1_inf = ResidualConv(inf_ch[0], inf_ch[1])\n",
    "            self.conv2_2_inf = ResidualConv(inf_ch[1], inf_ch[1])\n",
    "            self.conv3_1_inf = ResidualConv(inf_ch[1], inf_ch[2])\n",
    "            self.conv3_2_inf = ResidualConv(inf_ch[2], inf_ch[2])\n",
    "            self.conv4_inf   = MiniInceptionRes(inf_ch[2], inf_ch[3])\n",
    "            self.conv5_inf   = MiniInceptionRes(inf_ch[3], inf_ch[4])\n",
    "        else:\n",
    "            # placeholders\n",
    "            self.conv1_inf = None\n",
    "\n",
    "        # Precompute channel sizes so we never miscalculate:\n",
    "        self.rgb_ch = rgb_ch\n",
    "        self.inf_ch = inf_ch\n",
    "\n",
    "        # deepest fused channels\n",
    "        deepest_rgb = rgb_ch[4]   # 320\n",
    "        deepest_inf = inf_ch[4] if self.inf_in_ch > 0 else 0  # 160 or 0\n",
    "        self.fused_deep_ch = deepest_rgb + deepest_inf  # e.g. 480\n",
    "\n",
    "        # skip channel counts\n",
    "        skip4_ch = rgb_ch[3] + (inf_ch[3] if self.inf_in_ch > 0 else 0)  # 256 + 128 = 384\n",
    "        skip3_ch = rgb_ch[2] + (inf_ch[2] if self.inf_in_ch > 0 else 0)  # 160 + 96  = 256\n",
    "        skip2_ch = rgb_ch[1] + (inf_ch[1] if self.inf_in_ch > 0 else 0)  # 96  + 64  = 160\n",
    "        skip1_ch = rgb_ch[0] + (inf_ch[0] if self.inf_in_ch > 0 else 0)  # 32  + 32  = 64\n",
    "\n",
    "        # Decoding projections (concat upsampled fused/prev + skip) -> next-level channels\n",
    "        # decode4: (fused_deep) + skip4 -> project to skip3_ch\n",
    "        dec4_in_ch = self.fused_deep_ch + skip4_ch     # e.g. 480 + 384 = 864\n",
    "        dec4_out_ch = skip3_ch                         # 256\n",
    "\n",
    "        dec3_in_ch = dec4_out_ch + skip3_ch            # 256 + 256 = 512\n",
    "        dec3_out_ch = skip2_ch                         # 160\n",
    "\n",
    "        dec2_in_ch = dec3_out_ch + skip2_ch            # 160 +160 = 320\n",
    "        dec2_out_ch = skip1_ch                         # 64\n",
    "\n",
    "        dec1_in_ch = dec2_out_ch                       # 64\n",
    "        dec1_out_ch = dec1_in_ch                       # keep same, head maps to logits\n",
    "\n",
    "        # Residual projection convs\n",
    "        self.decode4_proj = ResidualConv(dec4_in_ch, dec4_out_ch)\n",
    "        self.decode3_proj = ResidualConv(dec3_in_ch, dec3_out_ch)\n",
    "        self.decode2_proj = ResidualConv(dec2_in_ch, dec2_out_ch)\n",
    "        self.decode1_proj = ResidualConv(dec1_in_ch, dec1_out_ch)\n",
    "\n",
    "        # Heads\n",
    "        self.head = nn.Conv2d(dec1_out_ch, self.n_class, kernel_size=1)\n",
    "        if self.deep_supervision:\n",
    "            self.head_ds3 = nn.Conv2d(dec3_out_ch, self.n_class, kernel_size=1)\n",
    "            self.head_ds4 = nn.Conv2d(dec4_out_ch, self.n_class, kernel_size=1)\n",
    "\n",
    "        # Optional SE after fusion\n",
    "        if self.use_se:\n",
    "            self.se = SEBlock(self.fused_deep_ch, reduction=8)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: B, C, H, W\n",
    "        assert x.shape[1] >= 3, \"input must contain at least 3 channels for RGB\"\n",
    "        x_rgb = x[:, :3, :, :]\n",
    "        x_inf = x[:, 3:, :, :] if self.inf_in_ch > 0 else None\n",
    "\n",
    "        #  RGB encode (store skips) \n",
    "        x_rgb = self.conv1_rgb(x_rgb)               # level1\n",
    "        x_rgb = F.max_pool2d(x_rgb, 2)\n",
    "        x_rgb = self.conv2_1_rgb(x_rgb)\n",
    "        x_rgb_p2 = self.conv2_2_rgb(x_rgb)          # skip level2\n",
    "        x_rgb = F.max_pool2d(x_rgb_p2, 2)\n",
    "        x_rgb = self.conv3_1_rgb(x_rgb)\n",
    "        x_rgb_p3 = self.conv3_2_rgb(x_rgb)          # skip level3\n",
    "        x_rgb = F.max_pool2d(x_rgb_p3, 2)\n",
    "        x_rgb_p4 = self.conv4_rgb(x_rgb)            # skip level4\n",
    "        x_rgb = F.max_pool2d(x_rgb_p4, 2)\n",
    "        x_rgb = self.conv5_rgb(x_rgb)               # deepest rgb\n",
    "\n",
    "        #  INF encode \n",
    "        if x_inf is not None:\n",
    "            x_inf = self.conv1_inf(x_inf)\n",
    "            x_inf = F.max_pool2d(x_inf, 2)\n",
    "            x_inf = self.conv2_1_inf(x_inf)\n",
    "            x_inf_p2 = self.conv2_2_inf(x_inf)\n",
    "            x_inf = F.max_pool2d(x_inf_p2, 2)\n",
    "            x_inf = self.conv3_1_inf(x_inf)\n",
    "            x_inf_p3 = self.conv3_2_inf(x_inf)\n",
    "            x_inf = F.max_pool2d(x_inf_p3, 2)\n",
    "            x_inf_p4 = self.conv4_inf(x_inf)\n",
    "            x_inf = F.max_pool2d(x_inf_p4, 2)\n",
    "            x_inf = self.conv5_inf(x_inf)\n",
    "        else:\n",
    "            \n",
    "            # create zero placeholders with correct channel counts so concat works seamlessly\n",
    "            B, _, Hd, Wd = x_rgb.shape\n",
    "            device = x_rgb.device\n",
    "            x_inf = torch.zeros(B, 0, Hd, Wd, device=device)  # deepest INF channels = 0\n",
    "            x_inf_p4 = None\n",
    "            x_inf_p3 = None\n",
    "            x_inf_p2 = None\n",
    "\n",
    "        #  fusion at deepest level \n",
    "        if x_inf.shape[1] == 0:\n",
    "            fused = x_rgb\n",
    "        else:\n",
    "            fused = torch.cat([x_rgb, x_inf], dim=1)\n",
    "\n",
    "        if self.use_se:\n",
    "            fused = self.se(fused)\n",
    "\n",
    "        #  decode level 4 \n",
    "        x = F.interpolate(fused, scale_factor=2.0, mode='nearest')  # up -> level4 spatial\n",
    "        # build skip4 (rgb_p4 + inf_p4 if available)\n",
    "        if x_inf is not None and x_inf_p4 is not None:\n",
    "            skip4 = torch.cat([x_rgb_p4, x_inf_p4], dim=1)\n",
    "        else:\n",
    "            skip4 = x_rgb_p4\n",
    "\n",
    "        # concat upsampled fused + skip4\n",
    "        x = torch.cat([x, skip4], dim=1)    # channels = fused_deep_ch + skip4_ch\n",
    "        x = self.decode4_proj(x)            # out channels = dec4_out_ch\n",
    "        ds4 = self.head_ds4(x) if self.deep_supervision else None\n",
    "\n",
    "        #  decode level 3 \n",
    "        x = F.interpolate(x, scale_factor=2.0, mode='nearest')\n",
    "        if x_inf is not None and x_inf_p3 is not None:\n",
    "            skip3 = torch.cat([x_rgb_p3, x_inf_p3], dim=1)\n",
    "        else:\n",
    "            skip3 = x_rgb_p3\n",
    "        x = torch.cat([x, skip3], dim=1)    # channels = dec4_out_ch + skip3_ch\n",
    "        x = self.decode3_proj(x)            # out channels = dec3_out_ch\n",
    "        ds3 = self.head_ds3(x) if self.deep_supervision else None\n",
    "\n",
    "        #  decode level 2 \n",
    "        x = F.interpolate(x, scale_factor=2.0, mode='nearest')\n",
    "        if x_inf is not None and x_inf_p2 is not None:\n",
    "            skip2 = torch.cat([x_rgb_p2, x_inf_p2], dim=1)\n",
    "        else:\n",
    "            skip2 = x_rgb_p2\n",
    "        x = torch.cat([x, skip2], dim=1)\n",
    "        x = self.decode2_proj(x)            # out channels = dec2_out_ch\n",
    "\n",
    "        # final upsample to original resolution \n",
    "        x = F.interpolate(x, scale_factor=2.0, mode='nearest')\n",
    "        x = self.decode1_proj(x)\n",
    "        main_logits = self.head(x)\n",
    "\n",
    "        if self.deep_supervision:\n",
    "            # ensure ds shapes match main_logits spatial size\n",
    "            ds3_up = F.interpolate(ds3, size=main_logits.shape[2:], mode='bilinear', align_corners=False)\n",
    "            ds4_up = F.interpolate(ds4, size=main_logits.shape[2:], mode='bilinear', align_corners=False)\n",
    "            # return (main, ds3_up, ds4_up)\n",
    "            return main_logits, ds3_up, ds4_up\n",
    "        else:\n",
    "            return main_logits\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \n",
    "        # Kaiming init for convs, BN ones and zeros\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='leaky_relu')\n",
    "                if getattr(m, 'bias', None) is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, (nn.BatchNorm2d,)):\n",
    "                if getattr(m, 'weight', None) is not None:\n",
    "                    nn.init.ones_(m.weight)\n",
    "                if getattr(m, 'bias', None) is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    \n",
    "    \n",
    "##############################\n",
    "# IoU Metric and Dice Loss\n",
    "##############################\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def dice_loss(pred, target, smooth=1.0):\n",
    "    \"\"\"\n",
    "    Computes the Dice Loss for binary segmentation.\n",
    "    Args:\n",
    "        pred (torch.Tensor): Predicted logits of shape (B, 1, H, W)\n",
    "        target (torch.Tensor): Ground truth mask of shape (B, 1, H, W)\n",
    "        smooth (float): Smoothing constant to avoid division by zero\n",
    "    Returns:\n",
    "        torch.Tensor: Scalar Dice Loss\n",
    "    \"\"\"\n",
    "    pred = torch.sigmoid(pred)  # Convert logits to probabilities\n",
    "\n",
    "    # Flatten each image in batch to compute per-sample Dice\n",
    "    pred = pred.contiguous().view(pred.size(0), -1)\n",
    "    target = target.contiguous().view(target.size(0), -1)\n",
    "\n",
    "    intersection = (pred * target).sum(dim=1)\n",
    "    dice = (2. * intersection + smooth) / (pred.sum(dim=1) + target.sum(dim=1) + smooth)\n",
    "\n",
    "    # Return mean Dice loss over batch\n",
    "    return 1 - dice.mean()\n",
    "\n",
    "\n",
    "def combined_loss(outputs, target, alpha=0.7):\n",
    "    \"\"\"\n",
    "    outputs can be either:\n",
    "     - single tensor (deep_supervision=False)\n",
    "     - tuple: (main, ds3, ds4)\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(outputs, tuple):\n",
    "        main, ds3, ds4 = outputs\n",
    "\n",
    "        loss_main = alpha * bce_loss(main, target) + (1 - alpha) * dice_loss(main, target)\n",
    "        loss_ds3  = alpha * bce_loss(ds3, target)  + (1 - alpha) * dice_loss(ds3, target)\n",
    "        loss_ds4  = alpha * bce_loss(ds4, target)  + (1 - alpha) * dice_loss(ds4, target)\n",
    "\n",
    "        # Weighted deep supervision\n",
    "        return loss_main + 0.5 * loss_ds3 + 0.25 * loss_ds4\n",
    "\n",
    "    else:\n",
    "        # Single output\n",
    "        return alpha * bce_loss(outputs, target) + (1 - alpha) * dice_loss(outputs, target)\n",
    "\n",
    "\n",
    "def iou_score(pred, gt, n_classes=2, eps=1e-10):\n",
    "\n",
    "    #  Handle MFNet deep supervision: get main output\n",
    "    if isinstance(pred, tuple):\n",
    "        pred = pred[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Binary segmentation: pred shape = (B,1,H,W)\n",
    "        if pred.shape[1] == 1:\n",
    "            pred = (pred > 0.1).long()  # threshold at 0.1\n",
    "        else:\n",
    "            pred = torch.argmax(pred, dim=1, keepdim=True)\n",
    "\n",
    "        pred = pred.squeeze(1)\n",
    "        gt = gt.squeeze(1)\n",
    "\n",
    "        iou_per_class = []\n",
    "\n",
    "        for cls in range(n_classes):\n",
    "            pred_cls = (pred == cls)\n",
    "            gt_cls = (gt == cls)\n",
    "\n",
    "            intersection = (pred_cls & gt_cls).sum().float()\n",
    "            union = (pred_cls | gt_cls).sum().float()\n",
    "\n",
    "            if union == 0:\n",
    "                iou_per_class.append(float('nan'))\n",
    "            else:\n",
    "                iou = (intersection + eps) / (union + eps)\n",
    "                iou_per_class.append(iou.item())\n",
    "\n",
    "        return np.nanmean(iou_per_class)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3517c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CHECKPOINT_PATH = \"/content/mfnet(big)_checkpoint.pth\"\n",
    "CHECKPOINT_PATH_drive = \"/content/drive/MyDrive/mfnet(big)_checkpoint.pth\"\n",
    "BEST_MODEL_PATH = \"/content/best_model.pth\"\n",
    "BEST_DICE_MODEL_PATH = \"/content/best_dice_model.pth\"\n",
    "\n",
    "####################\n",
    "# Training Setup\n",
    "####################\n",
    "model = MFNet(in_ch=16, n_class=1, use_se=True, deep_supervision=True).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.65, patience=3, min_lr=1e-11) #changing min_lr from 1e-6 to 5e-7\n",
    "\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    try:\n",
    "        checkpoint_1 = torch.load(BEST_MODEL_PATH, map_location=device)\n",
    "        checkpoint_2 = torch.load(BEST_DICE_MODEL_PATH, map_location=device)\n",
    "\n",
    "        model.load_state_dict(checkpoint_1['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint_2['optimizer_state_dict'])\n",
    "        \n",
    "        # loading with same lr again\n",
    "        # for param_group in optimizer.param_groups:\n",
    "          # param_group['lr'] = 1e-8\n",
    "        \n",
    "        start_epoch = checkpoint_1['epoch'] +1\n",
    "        print(f\"Loaded checkpoint from epoch {checkpoint_1['epoch']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load checkpoint \\n({e}). \\nStarting from scratch.\")\n",
    "else:\n",
    "    print(\"No checkpoint found - starting anew.\")\n",
    "\n",
    "#################\n",
    "# Data Loader\n",
    "#################\n",
    "DATA_DIR = \"/root/.cache/kagglehub/competitions/kaggle-competition-dl-f-2025\"\n",
    "X_train = np.load('/root/.cache/kagglehub/competitions/kaggle-competition-dl-f-2025/X_train_256.npy', mmap_mode='r')\n",
    "Y_train = np.load('/root/.cache/kagglehub/competitions/kaggle-competition-dl-f-2025/Y_train_256.npy', mmap_mode='r')\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Train mask shape:\", Y_train.shape, \"\\n\")\n",
    "\n",
    "indices = np.arange(len(X_train))\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.25, random_state=303)\n",
    "del indices\n",
    "train_ds = MultiSpectralDataset(X_train, Y_train, train_idx, augment=True, compute_stats=True)\n",
    "val_ds   = MultiSpectralDataset(X_train, Y_train, val_idx, augment=False, compute_stats=True)\n",
    "del X_train, Y_train\n",
    "BATCH_SIZE = 24\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d4ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(start_epoch=0,EPOCHS=300):\n",
    "\n",
    "    best_val_iou = 0.0\n",
    "    best_val_dice = 0.0\n",
    "\n",
    "    for epoch in range(start_epoch, EPOCHS):\n",
    "\n",
    "        # ------------------------ TRAIN ------------------------\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        pbar = tqdm(train_loader, desc=f\"Train {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "        for imgs, masks in pbar:\n",
    "            imgs = imgs.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            logits = model(imgs)\n",
    "\n",
    "            loss = combined_loss(logits, masks)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix(loss=total_loss / (pbar.n + 1))\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # ------------------------ VALIDATION ------------------------\n",
    "        model.eval()\n",
    "        val_iou_total = 0.0\n",
    "        val_count = 0\n",
    "        total_dice = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, masks in val_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                masks = masks.float()\n",
    "                masks = masks.to(device)\n",
    "\n",
    "                logits, _, _ = model(imgs)\n",
    "\n",
    "                # IoU @ threshold=0.1 (probabilities -> binary mask inside function)\n",
    "                iou = iou_score(logits, masks)\n",
    "                dice = dice_loss(logits, masks)            # both on GPU\n",
    "\n",
    "                total_dice += (1-dice)\n",
    "\n",
    "                if not math.isnan(iou):\n",
    "                    val_iou_total += iou\n",
    "                    val_count += 1\n",
    "\n",
    "        val_iou = (val_iou_total / val_count) if val_count > 0 else 0.0\n",
    "        val_dice = (total_dice / val_count) if val_count > 0 else 0.0\n",
    "\n",
    "        # ------------------------ SCHEDULER (on Dice) ------------------------\n",
    "        scheduler.step((val_dice))\n",
    "\n",
    "        # ------------------------ PRINT STATUS ------------------------\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}: \"\n",
    "            f\"TrainLoss={avg_train_loss:.4f}, \"\n",
    "            f\"Val IoU={val_iou:.4f}, \"\n",
    "            f\"Val Dice ={val_dice:.4f}, \"\n",
    "            f\"LR={optimizer.param_groups[0]['lr']:.2e}\"\n",
    "        )\n",
    "\n",
    "        # ------------------------ SAVE CHECKPOINT EVERY EPOCH ------------------------\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, CHECKPOINT_PATH)\n",
    "\n",
    "        # ------------------------ BEST IoU SAVE ------------------------\n",
    "        if val_iou > best_val_iou:\n",
    "            best_val_iou = val_iou\n",
    "            torch.save(checkpoint, BEST_MODEL_PATH)\n",
    "            print(f\"New BEST IoU model saved (Val IoU={best_val_iou:.4f})\\n\")\n",
    "\n",
    "        # ------------------------ BEST DICE SAVE ------------------------\n",
    "        if (val_dice) > best_val_dice:\n",
    "            best_val_dice = val_dice\n",
    "            torch.save(checkpoint, BEST_DICE_MODEL_PATH)\n",
    "            print(f\"New BEST Dice model saved (Val Dice={best_val_dice:.4f})\\n\")\n",
    "\n",
    "    print(f\"Best Validation IoU: {best_val_iou:.4f}\")\n",
    "    print(f\"Best Validation Dice: {best_val_dice:.4f}\")\n",
    "\n",
    "\n",
    "train_model(start_epoch=0, EPOCHS=150)  #for better training, train till 300 is suggested\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b7036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_inference(test_loader, model, device):\n",
    "    \n",
    "    use_model_for_test = model #inference_model\n",
    "    use_model_for_test.eval()\n",
    "\n",
    "    predictions = []\n",
    "    use_threshold = 0.099 #best_thr\n",
    "    with torch.no_grad():\n",
    "        for imgs in tqdm(test_loader, desc=\"Predicting \"):\n",
    "            imgs = imgs.to(device)\n",
    "            logits, _, _ = use_model_for_test(imgs)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()  # (B,1,H,W)\n",
    "            preds = (probs > use_threshold).astype(np.uint8)\n",
    "            for mask in preds:\n",
    "                predictions.append(mask.squeeze().astype(np.uint8).flatten())\n",
    "\n",
    "\n",
    "    #################\n",
    "    # submission.csv\n",
    "    #################\n",
    "    \n",
    "    # as per rules of the comeptition\n",
    "    submission = pd.DataFrame({\n",
    "        \"id\": np.arange(len(predictions)),\n",
    "        \"pixels\": [\",\".join(map(str, p)) for p in predictions]\n",
    "    })\n",
    "    SUBMISSION_PATH = \"submission.csv\"\n",
    "    submission.to_csv(SUBMISSION_PATH, index=False)\n",
    "    print(\"Saved\", SUBMISSION_PATH)\n",
    "\n",
    "    print(torch.cuda.memory_allocated())\n",
    "    # print(torch.cuda.memory_cached())# if deprecated, use torch.cuda.memory_reserved()\n",
    "    try:\n",
    "        print(torch.cuda.memory_cached())# if deprecated, use torch.cuda.max_memory_reserved()\n",
    "    except Exception as e:\n",
    "        print(torch.cuda.memory_reserved())\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "X_test  = np.load('/root/.cache/kagglehub/competitions/kaggle-competition-dl-f-2025/X_test_256.npy', mmap_mode='r')\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "indices = np.arange(len(X_test))\n",
    "test_ds = MultiSpectralDataset(X_test, Y=None,indices = indices,compute_stats=True, augment=False)\n",
    "del X_test\n",
    "test_loader = DataLoader(test_ds, batch_size=8, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# Initialize model\n",
    "model = MFNet(in_ch=16, n_class=1, use_se=True, deep_supervision=True).to(device)\n",
    "checkpoint = torch.load(BEST_MODEL_PATH, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "run_inference(test_loader, model, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
